---
layout: post
current: post
cover:  assets/images/Demonstration-cover.jpg
navigation: True
title: Comparison of deep learning models and development of web services for emotional analysis
date: 2021-06-20 08:00:00
tags: [Thesis]
class: post-template
subclass: 'post'
author: An Sung-Hyun
---


<p>[논문] 『감정분석을 위한 딥러닝 모델 비교 및 웹 서비스 개발』</p>
<p>[2021 한국디지털콘텐츠학회 국내학술대회 논문자료집 pp.119~120]</p>
<p>연구는 Python으로 진행하였고 Tensorflow, Pytorch 프레임워크가 사용됨</p>
<h2 id="Tensorflow Result"><mark>Tensorflow Result</mark></h2>
<h3 id="VGG16">VGG-16</h3>
<p><img src="assets/images/VGG16.png" width = "400" alt="VGG-16" /></p>
<h3 id="Densenet121">Densenet-121</h3>
<p><img src="assets/images/Densenet121.jpg" width = "400" alt="Densenet-121" /></p>
<h3 id="Densenet201">Densenet-201</h3>
<p><img src="assets/images/Densenet201.jpg" width = "400" alt="Densenet201" /></p>
<h3 id="Resnet50">Resnet 50</h3>
<p><img src="assets/images/Resnet50.png" width = "400" alt="Resnet50" /></p>
<h3 id="Resnet101">Resnet 101</h3>
<p><img src="assets/images/Resnet101.jpg" width = "400" alt="Resnet101" /></p>


<h2 id="Data Set"><mark>데이터 셋</mark></h2>
<p><img src="assets/images/Dataset.png" alt="Dataset Example" /></p>
<p>감정 분석기 개발을 위해 일반적으로 감정 분석에 사용되는 FER-2013 데이터 세트를 사용함. 48x48 크기의 대략 29000개의 이미지 데이터이며 7가지 감정으로 분류됨.
  하지만 혐오감이라는 한 가지 감정은 이미지가 충분하지 않아 이를 배제하고 AI를 훈련시키기로 함. 데이터셋의 불균형이
  정확성에 영향을 미친다고 들었기 때문. 쉬운 학습을 위해 데이터의 크기를 조정하고 배열하는 사전 과정을 거친 후 임의의 데이터를
  명확하게 분류할 수 있도록 이미지 확대(dimage_range=0.2, horizontal_flip=True, shear_range=0.2)를 적용함</p>

<h2 id="Face Detection"><mark>얼굴 인식</mark></h2>
<p><img src="assets/images/FaceDetection.jpg" alt="Dataset Example" /></p>
<p>OpenCV 라이브러리를 사용하여 얼굴 인식 기능을 구현함. 프로젝트의 목적을 위해 인식한 얼굴 좌표를 추출하는 코드만 추가함</p>

<h2 id="Demonstration View in Python"><mark>Python 환경에서의 시연</mark></h2>
<p><img src="assets/images/Demonstration.png" alt="Demonstration Image" /></p>
<p>위 사진은 분석 결과를 Softmax 방식으로 Python 환경에서 출력한 사진임</p>

<h2 id="Conclusion"><mark>결론</mark></h2>
<p>Tensorflow를 통해 구현된 딥 러닝 모델은 표준 그래프를 가지고 있지만 Pytorch는 그렇지 않았음. Pytorch가 제대로 작동하지 않은 주된 원인은 입력 형태라고 생각함.
48X48 이미지 데이터를 수집했고 텐서플로우는 입력 형태를 48X48로 설정할 수 있었으나 Pytorch는 설정할 수 없었음.
때문에 Pytorch는 형상을 입력해서 256x256 사이즈의 모델로 구축하고 학습시킬 수 밖에 없었음. 가지고 있는 데이터는 48X48인데 입력 모양이 256X256이라 제대로 학습되지 않은 것으로 추정됨.
유효성 검사 결과 VGG-16은 89%로 최고의 결과였음. 다만 densenet과 resnet과 VGG-16은 차이가 작기 때문에 최고의 모델이라고 단정하기는 어려움</p>

<h2 id="References"><mark>References</mark></h2>
<br/>
<p>
[1] Seung Hyeog Moon, “Analysis of AI-Applied Industry and Development Direction”, The Journal of the Convergence on Culture Technology(JCCT), 5:1, 77-82, 2019.
<br/>
[2] M. H. Jang, “Unplugged Education Program for Artificial Intelligence Education in Elementary Schools-Focus on ‘Constraint satisfaction problem’-”, Master D. thesis, Gyeongin National University of Education, Incheon, 2020.
<br/>
[3] Y. Adini, Y. Moses & S. Ullman, “Face Recognition: The problem of compensating for changes in illumination direction, IEEE Trans”. on Pattern Analysis and Machine Intelligence, 19(7), 721-732, 1997.
<br/>
[4] S. H. Kim, H. H. Kim & H. S. Lee. “An Improved Face Recognition Method Using SIFT-Grid”. Journal of Digital Convergence, 11(2), 299-307, 2013.
<br/>
[5] Liu, B., Sentiment, “Analysis : mining opinions, senti- ments, and emotions”, Cambridge University Press, 2015.
<br/>
[6] Suh, S. and Kim, J., “Research Trend of Deep Learningbased Sentiment Analysis”, Journal of Korea Multimedia Society, Vol. 20, No. 3, pp. 8-22, 2016.
<br/>
[7] Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K., “BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding”, NAACL-HLT, 2019. Yoo, S. and Jeong, O., An Intelligent Chatbot Utilizing BERT Model and Knowledge Graph, Journal of Society for e-Business Studies, Vol. 24, No. 3, pp. 87-98, 2019
<br/>
[8] TTA, “Sentiment Ontology for Social Web”, Telecommunications Technology Association Report TTAK.KO-10.0639/R1, 2013.
<br/>
[9] B. Liu, “Web Data Mining,” Springer, 2007.
<br/>
[10] D. Hussein, “A survey on sentiment analysis challenges,” Journal of King Saud University – Engineering Sciences, Vol.30, No.4, pp.330-338, 2018.
<br/>
[11] K.-J. Lee, J.-H. Kim, H.-W. Seo, and K.-S. Ryoo, “Feature weighting for opinion classification of comments on news articles,” Journal of the Korean Society of Marine Engineering, Vol.34, No.6, pp.871-879, 2010.
<br/>
[12] P. Turney, “Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews,” Proceedings of the Association for Computational Linguistics, pp.417–424, 2002.
<br/>
[13] E. Gilbert and C. J. Hutto, “VADER : A parsimonious rulebased model for sentiment analysis of social media text,” Proceedings of the 8th International Conference on Weblogs and Social Media, pp.216-225, 2014.
<br/>
[14] M. Taboada and J. Brooke, “Lexicon-based methods for sentiment analysis,” Computational Linguistics, Vol.37, No.2, pp.272–274, 2011.
<br/>
[15] L. Zhang, S. Wang, and B. Liu, “Deep learning for sentiment analysis: A survey,” arXiv:1801.07883, 2018.
<br/>
[16] OpenCV, https://ko.wikipedia.org/wiki/OpenCV, 2021.
<br/>
[17] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural Computation, 9(8), 1997.
<br/>
[18] G. Toderici, D. Vincent, N. Johnston, S. J. Hwang, D.Minnen,J. Shor, and M. Convell, “Full resolution image compression with recurrent neural networks,” arXiv preprint arXiv:1608.05148, 2016.
<br/>
[19] Very Deep Convolutional Networks for Large-Scale Image Recognition, https://arxiv.org/abs/1409.1556, 2015
<br/>
[20] A. Krizhevsky, I. Sutskever, and G. E. Hinton. “ImageNet classification with deep convolutional neural networks,”Communications of the ACM, vol. 60, no. 6, pp. 84-90, May 2017.
<br/>
[21] ] M. D. Zeiler and R. Fergus, “Visualizing and Understanding Convolutional Networks,” in Computer Vision-ECCV 2014, Springer pp. 818-833, 2014.
<br/>
[22] C. Szegedy et al.,“Going deeper with convolutions,” in 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.
<br/>
[23] He, K., Zhang, X., Ren, S., & Sun, J. “Deep residual learning for image recognition”, In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, 2016.
<br/>
[24] Automatic Hierarchical Classification of Kelps Using Deep Residual Features, https://www.researchgate.net/figure/ResNet-50-architecture-26-shown-with-the-residual-units-the-size-of-the-filters-and_fig1_338603223, 2015
<br/>
[25] G. Huang, Z. Liu, “Densely connected convolutional networks,” Proc. of the IEEE conference on computer vision and pattern recognition, Vol. 1, No. 2, pp. 3, 2017.
<br/>
[26] SqueezeNet: ALEXNET-LEVEL ACCURACY WITH 50X FEWER PARAMETERS AND 0.5MB MODEL SIZE,  https://arxiv.org/pdf/1602.07360v4.pdf, 2016
<br/>
[27] M. Tan, Q. V. Le. "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks." arXiv preprint arXiv:1905.11946, 2019.
<br/>
[28] Wide Residual Networks, https://arxiv.org/abs/1605.07146, 2016
<br/>
[29] 1000x Faster Data Augmentation, https://bair.berkeley.edu/blog/2019/06/07/data_aug/, 2019
<br/>
</p>
